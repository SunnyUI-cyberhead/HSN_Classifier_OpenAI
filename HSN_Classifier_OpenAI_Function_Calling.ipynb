{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f679ea2b",
   "metadata": {},
   "source": [
    "# HSN Classifier with OpenAI Function Calling\n",
    "\n",
    "This notebook:\n",
    "1. Loads the `HSN_SAC.xlsx` dataset.\n",
    "2. Preprocesses HSN codes and descriptions.\n",
    "3. Trains a dual-input Keras model.\n",
    "4. Defines a `hsn_classifier` function.\n",
    "5. Demonstrates OpenAI function-calling to invoke the classifier.\n",
    "\n",
    "**Prerequisites**:\n",
    "- Storing `HSN_SAC.xlsx` in the same directory.\n",
    "- Setting environment variable `OPENAI_API_KEY` to our OpenAI API key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64e3ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 25.1.1 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Sunny\\venvs\\hsn_tf_env\\Scripts\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# Installing dependencies\n",
    "!pip install --quiet pandas numpy scikit-learn tensorflow openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "db32926d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully loaded OPENAI_API_KEY (first 4 chars): sk-proj-TC\n"
     ]
    }
   ],
   "source": [
    "# Necessary Imports and environment setup\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import openai   \n",
    "\n",
    "# Reading the key from the environment and assign it\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not openai.api_key:\n",
    "    raise ValueError(\"Please set the OPENAI_API_KEY environment variable.\")\n",
    "\n",
    "print(\"✅ Successfully loaded OPENAI_API_KEY (first 4 chars):\", openai.api_key[:10])\n",
    "\n",
    "# ──────────────────────────────────────────\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5e900f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>\\nHSNCode</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>01</td>\n",
       "      <td>LIVE ANIMALS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0101</td>\n",
       "      <td>LIVE HORSES, ASSES, MULES AND HINNIES.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>01011010</td>\n",
       "      <td>LIVE HORSES, ASSES, MULES AND HINNIES PURE-BRE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>01011020</td>\n",
       "      <td>LIVE HORSES, ASSES, MULESANDHINNIES PURE-BRED ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>01011090</td>\n",
       "      <td>LIVE HORSES, ASSES, MULES AND HINNIES PURE-BRE...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  \\nHSNCode                                        Description\n",
       "0        01                                       LIVE ANIMALS\n",
       "1      0101             LIVE HORSES, ASSES, MULES AND HINNIES.\n",
       "2  01011010  LIVE HORSES, ASSES, MULES AND HINNIES PURE-BRE...\n",
       "3  01011020  LIVE HORSES, ASSES, MULESANDHINNIES PURE-BRED ...\n",
       "4  01011090  LIVE HORSES, ASSES, MULES AND HINNIES PURE-BRE..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading and inspecting the dataset\n",
    "import openpyxl  \n",
    "import pandas as pd\n",
    "\n",
    "sd = pd.read_excel(r\"C:\\Users\\Sunny\\venvs\\hsn_tf_env\\New folder (2)\\HSN_SAC.xlsx\")\n",
    "sd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88dce412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned column names: ['HSNCode', 'Description']\n"
     ]
    }
   ],
   "source": [
    "# Stripping whitespace/newlines from all columns\n",
    "sd.columns = sd.columns.str.strip()\n",
    "print(\"Cleaned column names:\", sd.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42cd0223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw column names in the spreadsheet:\n",
      "['HSNCode', 'Description']\n",
      "\n",
      " After renaming to 'raw_code' and 'description':\n",
      "['raw_code', 'description']\n"
     ]
    }
   ],
   "source": [
    "# Printing out the raw columns so we can see exactly what they are\n",
    "print(\"Raw column names in the spreadsheet:\")\n",
    "print(sd.columns.tolist())\n",
    "\n",
    "# Renaming to standardized names: \"raw_code\" and \"description\"\n",
    "sd = sd.rename(columns={\n",
    "    \"HSNCode\": \"raw_code\",      \n",
    "    \"HSN Code\": \"raw_code\",     \n",
    "    \"Description\": \"description\" \n",
    "})\n",
    "\n",
    "# If we see any other variation in the printed list, add it as another key in that dict.\n",
    "\n",
    "print(\"\\n After renaming to 'raw_code' and 'description':\")\n",
    "print(sd.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff9265b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 21568\n",
      "Shapes:\n",
      " X_code_train: (17254, 8)\n",
      " X_desc_train: (17254, 50)\n",
      " y_train: (17254, 21568)\n"
     ]
    }
   ],
   "source": [
    "# Encoding target (HSNCode) as categories\n",
    "le = LabelEncoder()\n",
    "sd[\"label\"] = le.fit_transform(sd[\"raw_code\"])  # using the exact name printed by sd.columns\n",
    "num_classes = len(le.classes_)\n",
    "print(\"Number of labels:\", num_classes)\n",
    "\n",
    "# Tokenizing HSN code (character-level)\n",
    "code_tokenizer = Tokenizer(char_level=True, filters=None, lower=False)\n",
    "code_tokenizer.fit_on_texts(sd[\"raw_code\"].astype(str))\n",
    "X_code_seq = code_tokenizer.texts_to_sequences(sd[\"raw_code\"].astype(str))\n",
    "MAX_CODE_LEN = max(len(x) for x in sd[\"raw_code\"].astype(str))\n",
    "X_code = pad_sequences(X_code_seq, maxlen=MAX_CODE_LEN, padding=\"post\")\n",
    "\n",
    "# Tokenize description (word-level)\n",
    "DESC_VOCAB_SIZE = 10000\n",
    "DESC_MAX_LEN = 50\n",
    "desc_tokenizer = Tokenizer(num_words=DESC_VOCAB_SIZE, oov_token=\"<OOV>\")\n",
    "desc_tokenizer.fit_on_texts(sd[\"description\"].astype(str))\n",
    "X_desc_seq = desc_tokenizer.texts_to_sequences(sd[\"description\"].astype(str))\n",
    "X_desc = pad_sequences(X_desc_seq, maxlen=DESC_MAX_LEN, padding=\"post\")\n",
    "\n",
    "# Preparing target one-hot\n",
    "y = tf.keras.utils.to_categorical(sd[\"label\"], num_classes=num_classes)\n",
    "\n",
    "# Splitting into train/validation\n",
    "X_code_train, X_code_val, X_desc_train, X_desc_val, y_train, y_val = train_test_split(\n",
    "    X_code, X_desc, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\" X_code_train:\", X_code_train.shape)\n",
    "print(\" X_desc_train:\", X_desc_train.shape)\n",
    "print(\" y_train:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35a430c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"HSN_Classifier\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"HSN_Classifier\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ desc_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ code_input          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ desc_emb            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,227,648</span> │ desc_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ code_emb            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │ code_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ desc_conv (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">82,048</span> │ desc_emb[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ code_lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,832</span> │ code_emb[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ desc_pool           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ desc_conv[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_layer        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ code_lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ desc_pool[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ concat_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │ dropout1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output_layer        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">21568</span>)     │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,782,272</span> │ dropout2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ desc_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ code_input          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ desc_emb            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │  \u001b[38;5;34m1,227,648\u001b[0m │ desc_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ code_emb            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │        \u001b[38;5;34m384\u001b[0m │ code_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ desc_conv (\u001b[38;5;33mConv1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m128\u001b[0m)   │     \u001b[38;5;34m82,048\u001b[0m │ desc_emb[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ code_lstm (\u001b[38;5;33mLSTM\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m24,832\u001b[0m │ code_emb[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ desc_pool           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ desc_conv[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_layer        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ code_lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ desc_pool[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout1 (\u001b[38;5;33mDropout\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ concat_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense1 (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m24,704\u001b[0m │ dropout1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout2 (\u001b[38;5;33mDropout\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ output_layer        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m21568\u001b[0m)     │  \u001b[38;5;34m2,782,272\u001b[0m │ dropout2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,141,888</span> (15.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,141,888\u001b[0m (15.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,141,888</span> (15.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,141,888\u001b[0m (15.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Building the dual-input Keras model\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import (\n",
    "    Input, Embedding, LSTM, Conv1D, GlobalMaxPooling1D,\n",
    "    concatenate, Dense, Dropout\n",
    ")\n",
    "\n",
    "# Code branch (character-level)\n",
    "code_input = Input(shape=(MAX_CODE_LEN,), name=\"code_input\")\n",
    "code_vocab_size = len(code_tokenizer.word_index) + 1  # +1 for padding token\n",
    "code_embedding_dim = 32  # arbitrary choice\n",
    "code_emb = Embedding(\n",
    "    input_dim=code_vocab_size,\n",
    "    output_dim=code_embedding_dim,\n",
    "    name=\"code_emb\"\n",
    ")(code_input)\n",
    "code_lstm_units = 64  # arbitrary choice\n",
    "code_lstm = LSTM(code_lstm_units, name=\"code_lstm\")(code_emb)\n",
    "\n",
    "# Description branch (word-level)\n",
    "desc_input = Input(shape=(DESC_MAX_LEN,), name=\"desc_input\")\n",
    "DESC_VOCAB_SIZE = len(desc_tokenizer.word_index) + 1\n",
    "desc_embedding_dim = 128  # arbitrary choice\n",
    "desc_emb = Embedding(\n",
    "    input_dim=DESC_VOCAB_SIZE,\n",
    "    output_dim=desc_embedding_dim,\n",
    "    name=\"desc_emb\"\n",
    ")(desc_input)\n",
    "desc_conv_filters = 128  # arbitrary choice\n",
    "desc_conv = Conv1D(\n",
    "    filters=desc_conv_filters,\n",
    "    kernel_size=5,         # arbitrary\n",
    "    activation=\"relu\",\n",
    "    name=\"desc_conv\"\n",
    ")(desc_emb)\n",
    "desc_pool = GlobalMaxPooling1D(name=\"desc_pool\")(desc_conv)\n",
    "\n",
    "# Merging and classification head\n",
    "merged = concatenate([code_lstm, desc_pool], name=\"concat_layer\")\n",
    "dropout_rate = 0.4  # arbitrary choice\n",
    "x = Dropout(dropout_rate, name=\"dropout1\")(merged)\n",
    "dense_units = 128  # arbitrary choice\n",
    "x = Dense(dense_units, activation=\"relu\", name=\"dense1\")(x)\n",
    "x = Dropout(dropout_rate, name=\"dropout2\")(x)\n",
    "output = Dense(num_classes, activation=\"softmax\", name=\"output_layer\")(x)\n",
    "\n",
    "model = Model(inputs=[code_input, desc_input], outputs=output, name=\"HSN_Classifier\")\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ea9a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "540/540 - 78s - 144ms/step - accuracy: 1.7387e-04 - loss: 9.3342 - val_accuracy: 0.0000e+00 - val_loss: 11.9784\n",
      "Epoch 2/10\n",
      "540/540 - 30s - 56ms/step - accuracy: 6.9549e-04 - loss: 9.0824 - val_accuracy: 0.0000e+00 - val_loss: 12.3790\n",
      "Epoch 3/10\n",
      "540/540 - 29s - 55ms/step - accuracy: 0.0018 - loss: 8.7917 - val_accuracy: 0.0000e+00 - val_loss: 12.8206\n",
      "Epoch 4/10\n",
      "540/540 - 29s - 54ms/step - accuracy: 0.0039 - loss: 8.4573 - val_accuracy: 0.0000e+00 - val_loss: 13.1907\n",
      "Epoch 5/10\n",
      "540/540 - 29s - 54ms/step - accuracy: 0.0069 - loss: 8.0928 - val_accuracy: 0.0000e+00 - val_loss: 13.5888\n",
      "Epoch 6/10\n",
      "540/540 - 29s - 54ms/step - accuracy: 0.0118 - loss: 7.7192 - val_accuracy: 0.0000e+00 - val_loss: 13.9630\n",
      "Epoch 7/10\n",
      "540/540 - 29s - 54ms/step - accuracy: 0.0155 - loss: 7.3911 - val_accuracy: 0.0000e+00 - val_loss: 14.4529\n",
      "Epoch 8/10\n",
      "540/540 - 29s - 54ms/step - accuracy: 0.0234 - loss: 7.0701 - val_accuracy: 0.0000e+00 - val_loss: 14.8802\n",
      "Epoch 9/10\n",
      "540/540 - 29s - 54ms/step - accuracy: 0.0332 - loss: 6.7549 - val_accuracy: 0.0000e+00 - val_loss: 15.3590\n",
      "Epoch 10/10\n",
      "540/540 - 29s - 54ms/step - accuracy: 0.0430 - loss: 6.5069 - val_accuracy: 0.0000e+00 - val_loss: 15.6591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Training the model & saving artifacts\n",
    "\n",
    "history = model.fit(\n",
    "    {\"code_input\": X_code_train, \"desc_input\": X_desc_train},\n",
    "    y_train,\n",
    "    validation_data=(\n",
    "        {\"code_input\": X_code_val, \"desc_input\": X_desc_val},\n",
    "        y_val\n",
    "    ),\n",
    "    epochs=10,            \n",
    "    batch_size=32,       # arbitrary batch size\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Saving model + tokenizers + label encoder + constants\n",
    "model.save(\"hsn_classifier_model.h5\")\n",
    "\n",
    "with open(\"code_tokenizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(code_tokenizer, f)\n",
    "with open(\"desc_tokenizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(desc_tokenizer, f)\n",
    "with open(\"label_encoder.pkl\", \"wb\") as f:\n",
    "    pickle.dump(le, f)\n",
    "\n",
    "# Saving the fixed constants\n",
    "with open(\"constants.pkl\", \"wb\") as f:\n",
    "    pickle.dump({\"MAX_CODE_LEN\": MAX_CODE_LEN, \"DESC_MAX_LEN\": DESC_MAX_LEN}, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bdc0b247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Model loaded successfully.\n",
      " Tokenizers and label encoder loaded successfully.\n",
      " Constants loaded: MAX_CODE_LEN = 8, DESC_MAX_LEN = 50\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      " hsn_classifier output: {'predicted_hsn_code': '8521', 'confidence': 0.006479457952082157}\n"
     ]
    }
   ],
   "source": [
    "# Loading the model/tokenizers/constants \n",
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Loading the Keras model\n",
    "try:\n",
    "    _hsn_model = load_model(\"hsn_classifier_model.h5\")\n",
    "    print(\" Model loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(\" Failed to load model:\", e)\n",
    "\n",
    "# Loading the code_tokenizer, desc_tokenizer, and label_encoder\n",
    "try:\n",
    "    with open(\"code_tokenizer.pkl\", \"rb\") as f:\n",
    "        _code_tokenizer = pickle.load(f)\n",
    "    with open(\"desc_tokenizer.pkl\", \"rb\") as f:\n",
    "        _desc_tokenizer = pickle.load(f)\n",
    "    with open(\"label_encoder.pkl\", \"rb\") as f:\n",
    "        _label_encoder = pickle.load(f)\n",
    "    print(\" Tokenizers and label encoder loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(\" Failed to load tokenizer/label encoder:\", e)\n",
    "\n",
    "# Loading padding constants\n",
    "try:\n",
    "    with open(\"constants.pkl\", \"rb\") as f:\n",
    "        consts = pickle.load(f)\n",
    "    MAX_CODE_LEN = consts[\"MAX_CODE_LEN\"]\n",
    "    DESC_MAX_LEN = consts[\"DESC_MAX_LEN\"]\n",
    "    print(f\" Constants loaded: MAX_CODE_LEN = {MAX_CODE_LEN}, DESC_MAX_LEN = {DESC_MAX_LEN}\")\n",
    "except Exception as e:\n",
    "    print(\" Failed to load constants.pkl:\", e)\n",
    "\n",
    "# Defining the inference function if not already defined \n",
    "def hsn_classifier(hsn_code: str, description: str) -> dict:\n",
    "    \n",
    "    # Preprocessing the code\n",
    "    code_seq = _code_tokenizer.texts_to_sequences([hsn_code])\n",
    "    code_input = pad_sequences(code_seq, maxlen=MAX_CODE_LEN, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "    # Preprocessing the description\n",
    "    desc_seq = _desc_tokenizer.texts_to_sequences([description])\n",
    "    desc_input = pad_sequences(desc_seq, maxlen=DESC_MAX_LEN, padding=\"post\", truncating=\"post\")\n",
    "\n",
    "    # Predicting\n",
    "    probs = _hsn_model.predict({\"code_input\": code_input, \"desc_input\": desc_input})\n",
    "    idx = int(np.argmax(probs, axis=1)[0])\n",
    "    predicted_code = _label_encoder.inverse_transform([idx])[0]\n",
    "    confidence = float(probs[0][idx])\n",
    "\n",
    "    return {\n",
    "        \"predicted_hsn_code\": str(predicted_code),\n",
    "        \"confidence\": confidence\n",
    "    }\n",
    "\n",
    "# Running a quick “sanity check” \n",
    "sample_code = \"1006\"   \n",
    "sample_desc = \"Rice, semi-milled or wholly milled, whether or not polished or glazed\"\n",
    "\n",
    "try:\n",
    "    result = hsn_classifier(sample_code, sample_desc)\n",
    "    print(\" hsn_classifier output:\", result)\n",
    "except Exception as e:\n",
    "    print(\" hsn_classifier(…) raised an error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f6eede2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY starts with: sk-proj-TC …\n",
      " GPT replied: Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from openai import AuthenticationError, RateLimitError, OpenAIError\n",
    "\n",
    "# (Optional) confirming our key is loaded:\n",
    "print(\"OPENAI_API_KEY starts with:\", os.getenv(\"OPENAI_API_KEY\")[:10], \"…\")\n",
    "\n",
    "# A simple chat call, catching the proper exceptions:\n",
    "try:\n",
    "    resp = openai.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\":\"user\",\"content\":\"Hello, GPT!\"}],\n",
    "        \n",
    "    )\n",
    "    print(\" GPT replied:\", resp.choices[0].message.content)\n",
    "except AuthenticationError as ae:\n",
    "    print(\" AuthenticationError—your API key might be invalid:\", ae)\n",
    "except RateLimitError as re:\n",
    "    print(\" RateLimitError—quota exceeded or too many requests:\", re)\n",
    "except OpenAIError as oe:\n",
    "    print(\" Other OpenAI API error:\", oe)\n",
    "except Exception as e:\n",
    "    print(\" Some other exception occurred:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "76cb4b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Running HSN agent with sample input…\n",
      "\n",
      " GPT’s first reply (with function_call or direct content):\n",
      "{\n",
      "  \"role\": \"assistant\",\n",
      "  \"function_call\": {\n",
      "    \"name\": \"hsn_classifier\",\n",
      "    \"arguments\": \"{\\\"hsn_code\\\":\\\"1006.30\\\",\\\"description\\\":\\\"Rice, semi-milled or wholly milled, whether or not polished or glazed\\\"}\"\n",
      "  },\n",
      "  \"content\": null\n",
      "}\n",
      "\n",
      " GPT asked to call: hsn_classifier with args: {'hsn_code': '1006.30', 'description': 'Rice, semi-milled or wholly milled, whether or not polished or glazed'}\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
      " Local hsn_classifier returned: {'predicted_hsn_code': '61130000', 'confidence': 0.003788026748225093}\n",
      "\n",
      "Final assistant reply (after function call):\n",
      "The HSN code '1006.30' refers to \"Rice, semi-milled or wholly milled, whether or not polished or glazed.\" This categorization is used in trade to classify rice that has been processed to remove some or all of the outer bran layer and may also be polished or glazed to improve its appearance and cooking qualities. Let me know if you need more information!\n",
      "\n",
      "→ Agent’s final response: The HSN code '1006.30' refers to \"Rice, semi-milled or wholly milled, whether or not polished or glazed.\" This categorization is used in trade to classify rice that has been processed to remove some or all of the outer bran layer and may also be polished or glazed to improve its appearance and cooking qualities. Let me know if you need more information!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "import openai\n",
    "from openai import AuthenticationError, RateLimitError, OpenAIError\n",
    "\n",
    "# Defining our function schema exactly as before\n",
    "function_spec = {\n",
    "    \"name\": \"hsn_classifier\",\n",
    "    \"description\": \"Given an HSN code and description, return the predicted 8-digit HSN code and confidence.\",\n",
    "    \"parameters\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"hsn_code\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The raw HSN code to validate\"\n",
    "            },\n",
    "            \"description\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The item’s description in plain English\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"hsn_code\", \"description\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# A small retry wrapper to handle transient 429s \n",
    "def safe_chat_completion(**kwargs):\n",
    "    for attempt in range(3):\n",
    "        try:\n",
    "            return openai.chat.completions.create(**kwargs)\n",
    "        except RateLimitError:\n",
    "            print(f\"[Attempt {attempt+1}] RateLimitError — sleeping 1s…\")\n",
    "            time.sleep(1)\n",
    "    raise RuntimeError(\"RateLimitError persisted after 3 retries.\")\n",
    "\n",
    "\n",
    "# The “run_hsn_agent” function:\n",
    "def run_hsn_agent(user_code: str, user_desc: str) -> str:\n",
    "    \n",
    "# Asking GPT whether to call our function\n",
    "    try:\n",
    "        initial_resp = safe_chat_completion(\n",
    "            model=\"gpt-4o\",  # use a model you have confirmed works\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": (\n",
    "                        f\"I have HSN code '{user_code}' and description '{user_desc}'. \"\n",
    "                        \"Please verify or correct the HSN code and tell me how confident you are.\"\n",
    "                    )\n",
    "                }\n",
    "            ],\n",
    "            functions=[function_spec],\n",
    "            function_call=\"auto\"\n",
    "        )\n",
    "    except AuthenticationError as ae:\n",
    "        raise RuntimeError(\" AuthenticationError: invalid or missing API key\") from ae\n",
    "    except RateLimitError as re:\n",
    "        raise RuntimeError(\" RateLimitError: no remaining quota or too many requests\") from re\n",
    "    except OpenAIError as oe:\n",
    "        raise RuntimeError(\" Other OpenAI API error\") from oe\n",
    "\n",
    "    # Grabbing the single message that the model returned\n",
    "    message = initial_resp.choices[0].message\n",
    "\n",
    "    # Printing the content & function_call (if any)\n",
    "    print(\"\\n GPT’s first reply (with function_call or direct content):\")\n",
    "    print(json.dumps({\n",
    "        \"role\": message.role,\n",
    "        # message.function_call is either None or an object with .name and .arguments\n",
    "        \"function_call\": ( \n",
    "            {\n",
    "                \"name\": message.function_call.name,\n",
    "                \"arguments\": message.function_call.arguments\n",
    "            } \n",
    "            if message.function_call is not None else None\n",
    "        ),\n",
    "        \"content\": message.content\n",
    "    }, indent=2))\n",
    "\n",
    "    # If GPT requested a function call…\n",
    "    if message.function_call is not None:\n",
    "        func_name = message.function_call.name\n",
    "        # arguments is a JSON‐encoded string, so load it\n",
    "        func_args = json.loads(message.function_call.arguments)\n",
    "        print(f\"\\n GPT asked to call: {func_name} with args: {func_args}\")\n",
    "\n",
    "        if func_name == \"hsn_classifier\":\n",
    "            # Run your local inference function\n",
    "            func_response = hsn_classifier(\n",
    "                hsn_code=func_args.get(\"hsn_code\", \"\"),\n",
    "                description=func_args.get(\"description\", \"\")\n",
    "            )\n",
    "            print(\" Local hsn_classifier returned:\", func_response)\n",
    "        else:\n",
    "            raise RuntimeError(f\"Unexpected function name: {func_name}\")\n",
    "\n",
    "        # Sending the function’s output back to GPT\n",
    "        second_resp = safe_chat_completion(\n",
    "            model=\"gpt-4o\",\n",
    "            messages=[\n",
    "                # Re‐sending the original user message (optional but recommended)\n",
    "                {\"role\": \"user\", \"content\": f\"I asked about HSN '{user_code}' and '{user_desc}'.\"},\n",
    "                # The assistant’s request to call the function\n",
    "                message,\n",
    "                # Our function’s response as a “function” role\n",
    "                {\n",
    "                    \"role\": \"function\",\n",
    "                    \"name\": func_name,\n",
    "                    \"content\": json.dumps(func_response)\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        final_msg = second_resp.choices[0].message\n",
    "        print(\"\\nFinal assistant reply (after function call):\")\n",
    "        print(final_msg.content)\n",
    "        return final_msg.content\n",
    "\n",
    "    else:\n",
    "        # If GPT replied directly without calling the function\n",
    "        print(\"\\n GPT replied directly (no function call).\")\n",
    "        print(message.content)\n",
    "        return message.content\n",
    "\n",
    "\n",
    "#Finally, run the HSN agent on a sample code + description:\n",
    "\n",
    "sample_code = \"1006.30\"\n",
    "sample_desc = \"Rice, semi-milled or wholly milled, whether or not polished or glazed\"\n",
    "\n",
    "print(\"\\n Running HSN agent with sample input…\")\n",
    "agent_reply = run_hsn_agent(sample_code, sample_desc)\n",
    "print(\"\\n→ Agent’s final response:\", agent_reply)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hsn_tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
